{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a30a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "'''def clean_company_name(name: str) -> str:\n",
    "    \"\"\"Normalize stock names to plain company names.\"\"\"\n",
    "    name = re.sub(r'\\bCommon Stock\\b', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\bOrdinary Shares?\\b', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\bDepositary Shares?.*', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\bClass [A-Z]\\b', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\bLtd\\b', 'Limited', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name'''\n",
    "\n",
    "# Load both ticker lists\n",
    "#nyse_df = pd.read_csv(\"nyse_screener.csv\")\n",
    "#nasdaq_df = pd.read_csv(\"nasdaq_screener.csv\")\n",
    "Top_100 = pd.read_csv(\"Top_100.csv\")\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "#all_tickers = pd.concat([nyse_df, nasdaq_df], ignore_index=True)\n",
    "\n",
    "# Normalize column names just in case\n",
    "#all_tickers.columns = [col.strip().lower() for col in all_tickers.columns]\n",
    "Top_100.columns = [col.strip().lower() for col in Top_100.columns]\n",
    "\n",
    "# Clean names\n",
    "#all_tickers['clean_name'] = all_tickers['name'].apply(clean_company_name)\n",
    "\n",
    "# Create dictionaries for fast lookups\n",
    "ticker_to_name = dict(zip(Top_100['symbol'].str.upper(), Top_100['name']))\n",
    "valid_tickers = set(ticker_to_name.keys())\n",
    "company_names = [name.lower() for name in ticker_to_name.values()]\n",
    "name_to_ticker = {name.lower(): symbol for symbol, name in ticker_to_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf6b8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pre_processed_sub[\"Companies\"] = pre_processed_sub[\"selftext\"].apply(lambda x: extract_ner_entities(nlp, x, similarity_threshold=60))\\nprint(get_dict_top_companies(pre_processed_sub, \\'Companies\\'))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import warnings\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "#model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#to be ran per comment\n",
    "def extract_ner_entities(model, text, similarity_threshold=90):\n",
    "    \n",
    "    BLACKLIST = {'ev', 'covid', 'etf', 'nyse', 'sec', 'spac', 'fda', 'treasury', 'covid-19', 'rrsp', 'tfsa','fed', 'Reuters aggregated](https://www.streetinsider.com/Reuters'.lower()}\n",
    "    doc = model(text)\n",
    "    detected_companies = []\n",
    "\n",
    "    #Detect companies via spaCy NER\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\" and ent.text.lower() not in BLACKLIST:\n",
    "            org_name = ent.text.strip()\n",
    "            # Fuzzy match against official company names from csv file\n",
    "            match, score, _ = process.extractOne(org_name.lower(), company_names, scorer=fuzz.token_sort_ratio)\n",
    "            if score >= similarity_threshold:\n",
    "                matched_ticker = name_to_ticker[match]\n",
    "                canonical_name = ticker_to_name[matched_ticker]\n",
    "                detected_companies.append(canonical_name)\n",
    "            else:\n",
    "                #keeps companies not in csv file maybe delete later\n",
    "                detected_companies.append(org_name)\n",
    "\n",
    "    # --- Match stock tickers in text ---\n",
    "    for token in doc:\n",
    "        token_text = token.text.strip()\n",
    "\n",
    "        # Handle tickers with $ prefix, e.g. $AAPL\n",
    "        if token_text.startswith(\"$\"):\n",
    "            token_text = token_text[1:]\n",
    "\n",
    "        # Check if itâ€™s a valid ticker symbol\n",
    "        if token_text in valid_tickers:\n",
    "            company_name = ticker_to_name.get(token_text)\n",
    "            detected_companies.append(company_name)\n",
    "\n",
    "\n",
    "    return list(set(detected_companies))\n",
    "\n",
    "\n",
    "def get_dict_top_companies(dataset, column_name, top_companies=10):\n",
    "    company_counter = dict()\n",
    "    for companies in dataset[column_name]:\n",
    "        for company in companies:\n",
    "            if company in company_counter:  \n",
    "                company_counter[company] += 1\n",
    "            else:\n",
    "                company_counter[company] = 1\n",
    "    sorted_dict = dict(sorted(company_counter.items(), key=lambda x: x[1], reverse=True))\n",
    "    top = dict()\n",
    "    for company, count in list(sorted_dict.items())[:top_companies]:\n",
    "        top[company] = count\n",
    "\n",
    "    return top\n",
    "\n",
    "#Use this on Emre's code. \n",
    "'''pre_processed_sub[\"Companies\"] = pre_processed_sub[\"selftext\"].apply(lambda x: extract_ner_entities(nlp, x, similarity_threshold=60))\n",
    "print(get_dict_top_companies(pre_processed_sub, 'Companies'))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
